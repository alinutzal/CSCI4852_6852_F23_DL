{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSCI 4852 & 6952: Deep Learning (Spring 2023)  \n",
    "\n",
    "Instructor: Alina Lazar (alazar@ysu.edu)  \n",
    "GitHub repository:https://github.com/alinutzal/CSCI-xx52-Deep-Learning-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/adaline-concept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions. The derivative and training procedure are identical to Adaline though. You can compare the two notebooks (this one and `adaline-sgd.ipynb`) side by side as shown below to see the relationship:\n",
    "\n",
    "![](figures/adaline-vs-linreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.942094</td>\n",
       "      <td>-0.835856</td>\n",
       "      <td>-22.324428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.222445</td>\n",
       "      <td>-0.403177</td>\n",
       "      <td>-52.121493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.112466</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-57.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.403459</td>\n",
       "      <td>-0.412272</td>\n",
       "      <td>-27.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>-0.499017</td>\n",
       "      <td>-9.804714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "995 -0.942094 -0.835856 -22.324428\n",
       "996  1.222445 -0.403177 -52.121493\n",
       "997 -0.112466 -1.688230 -57.043196\n",
       "998 -0.403459 -0.412272 -27.701833\n",
       "999  0.021351 -0.499017  -9.804714"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/linreg-data.csv', index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([382, 974, 946,  31, 512,  42, 918, 564, 827, 227, 261, 737, 322, 710,\n",
      "        502, 309, 598, 111, 949, 884, 730, 137, 659, 336, 811, 802, 703, 114,\n",
      "        420, 622,  56,   4, 647,  39, 376, 126, 859, 226, 680, 938, 864, 618,\n",
      "        352, 443, 593, 466, 848, 788, 972, 397, 153,  90, 862, 727, 815, 707,\n",
      "        505, 850, 898, 591, 970, 828, 424, 148, 274, 930, 224, 432, 273, 840,\n",
      "        646, 990, 115, 299, 933, 436, 790, 685, 794, 533, 643, 752, 820, 654,\n",
      "        398, 316, 328, 857, 179,  50, 347, 426, 803, 708, 983, 521, 265, 193,\n",
      "        416, 377, 477, 408, 676, 448, 873, 899, 404, 735, 989, 319, 936, 337,\n",
      "        865, 198, 749, 101, 867, 616, 213, 937, 769, 422, 393, 338, 615, 510,\n",
      "        440, 209,  84, 953, 457, 143, 614, 635, 779,  68, 628, 585, 607, 777,\n",
      "        549, 582, 694, 776, 467, 360,  43, 696, 999, 468, 538, 581, 768, 561,\n",
      "        410, 249, 891, 421, 514, 982, 733,  59, 296, 920,  79, 900,  32, 959,\n",
      "        774, 293, 637, 839, 892, 683, 460, 493, 588, 371, 638, 608, 731, 994,\n",
      "        734, 838, 709, 942, 158, 640, 492, 814, 599, 728, 240, 450, 556, 553,\n",
      "        200,  12, 315,  18, 853, 331, 998,  73, 278, 229, 121, 164,  66,  94,\n",
      "        454, 910, 604, 253, 562, 559,  30, 955, 325, 660, 879, 858,  21,  23,\n",
      "        566, 678, 437, 162, 409, 417, 829, 807, 470, 355, 589, 365, 570, 881,\n",
      "        182, 841,   0,  81, 967, 546, 362, 509,  75, 621, 271, 359, 481, 208,\n",
      "         92, 387, 147, 302, 464,  62,   9, 524, 218, 847,  20, 746, 671, 692,\n",
      "        369, 189, 742, 294, 975, 554, 286, 384, 220, 587, 131, 136, 755, 935,\n",
      "        652, 991, 415, 204, 704, 834,  80, 761, 199, 655, 907, 507, 677,  37,\n",
      "        134, 600,  91, 495,  61, 258, 276, 661, 449, 445, 161, 285, 665, 919,\n",
      "        943, 116, 763, 697, 186, 670, 306, 215, 388, 732, 187, 248, 531, 413,\n",
      "        429, 796, 687, 517, 619, 367, 719, 308, 488, 486, 175, 926,  70, 843,\n",
      "        980, 897, 144, 711, 977, 988,  83, 476,  96, 651, 155, 243, 197, 390,\n",
      "        965, 267, 597, 255, 813, 312, 403, 917, 668, 522, 806, 740, 523, 272,\n",
      "        241, 812,  13, 172,  63,   6, 826, 639, 333, 765,   3, 631, 423, 875,\n",
      "        332,  51, 801, 552, 957, 305, 221, 590, 568, 104, 690, 130, 279, 107,\n",
      "        462, 207, 223, 833, 573, 744, 452, 270, 396, 762, 836, 852, 964, 399,\n",
      "        715,  25, 518, 882, 320, 612, 725, 173, 944, 706, 247, 214, 743, 976,\n",
      "        569, 641,  87, 383, 821, 940, 157, 771, 613,  85, 401, 363, 118, 620,\n",
      "        251, 968, 787, 311, 876, 720, 482, 366, 888, 675, 201, 166, 905, 909,\n",
      "        192, 903, 451, 550, 916, 889, 254, 497, 823, 908,  26, 479, 653,  55,\n",
      "        234, 345, 565, 617,  36, 832, 778, 551, 185, 686, 837, 745, 381, 751,\n",
      "        780, 281, 979, 530, 784, 630, 924, 500, 257, 915, 527, 191, 540, 178,\n",
      "         69, 798, 292, 869, 165,  14, 326, 856, 106,  28, 117, 385,  67, 405,\n",
      "        487, 555, 541, 346, 945, 484, 138, 981, 455, 648, 239, 791, 571, 145,\n",
      "        606, 863, 212, 901, 682, 681, 458, 810, 461, 624, 210, 339, 871, 542,\n",
      "        358, 430, 127, 334, 605, 428, 997, 375, 987, 928, 300, 361, 713, 475,\n",
      "        775, 370, 544, 739, 504, 307, 395, 202, 103, 701, 323, 472, 235, 934,\n",
      "        792, 501, 578, 870, 456, 176, 356, 960, 927,  40, 310, 893, 644, 491,\n",
      "         54,  33, 442, 868,  53, 894, 818,  89, 350, 913, 349,  44, 602, 113,\n",
      "        642, 914, 645,  64, 611, 575, 583, 194, 392, 263, 984, 283, 969, 447,\n",
      "        170, 557, 280, 912, 951, 985,  78, 262, 629, 636, 722, 545, 861, 886,\n",
      "        329, 537, 978, 684, 961, 469,  60, 689, 691, 222, 729, 948, 819, 754,\n",
      "        498, 160, 610, 992, 966, 250,  99, 766, 721, 494, 478, 649, 317, 489,\n",
      "        851, 230, 895,   5, 211, 764, 102, 887, 439, 135,  57, 835, 592,  45,\n",
      "        767,  77, 289, 657, 548, 297, 129, 340, 174, 872, 238, 922, 921, 577,\n",
      "        496, 277, 184, 100, 800, 797, 378, 232,  17, 699, 341,  35, 855, 298,\n",
      "        535, 662, 756, 205,  97, 357, 374, 389, 282, 169, 758, 986, 705, 150,\n",
      "        954, 741, 658, 386, 673, 896,  86, 772, 781, 516, 716, 154, 627, 849,\n",
      "         19,  72, 860, 124, 499, 485, 406, 444, 667, 480, 736, 275, 572, 718,\n",
      "        508, 724, 825, 539,  49, 152, 391, 402, 808, 318, 669, 816, 188, 885,\n",
      "         29, 149, 266, 717, 354, 344, 906, 418, 866, 503, 526, 513, 284, 693,\n",
      "         24, 650, 128, 525, 679, 364, 105, 726,  74, 971, 747, 563, 712, 603,\n",
      "         82, 109, 343, 228, 168, 269, 672, 252, 110, 931, 714, 962, 219, 490,\n",
      "        196, 783, 414, 237, 142, 256, 809,  11, 782, 327, 133, 574, 817, 216,\n",
      "        795,  34, 163, 584, 753, 446, 793,  46, 939, 656, 911, 633,  41, 700,\n",
      "        151, 950, 663, 335, 534, 141, 594, 932, 483, 702, 314, 952, 321, 474,\n",
      "        125,  88, 108, 303, 519,  98, 973, 925,  71, 799, 441, 830, 459,  93,\n",
      "        407,  48, 330, 435, 139, 351, 324, 596, 246, 304, 434, 880, 288, 463,\n",
      "        419, 929, 770, 586, 412, 579,  38, 506, 532, 854, 295, 471, 394,  27,\n",
      "        804,   7, 558, 904, 181, 438, 231, 845, 786, 698, 140,  76, 260, 805,\n",
      "        626, 373,  16, 465, 511,  47, 842, 664, 313, 112, 846, 878, 433, 601,\n",
      "        760, 877, 688, 264, 547, 132, 883, 956, 425, 773, 844, 119, 190, 453,\n",
      "        567, 379,   8, 695, 259, 195, 822, 674, 122, 666, 560, 372, 183,  65,\n",
      "         52, 632, 995, 528, 236, 353, 941, 171, 923, 225, 120, 203, 123,  10,\n",
      "        831, 167, 785, 738, 623, 342, 824, 576, 159,  95, 368, 268, 947, 993,\n",
      "        748, 348, 380, 789, 759, 180, 242, 291,  15, 244, 902, 625, 958, 146,\n",
      "         58, 996, 515, 634, 427,   2, 177, 609, 890, 431, 723, 301,  22, 580,\n",
      "        963, 411, 750, 595, 233, 520, 287, 245, 543, 757,   1, 874, 529, 206,\n",
      "        217, 473, 400, 536, 156, 290])\n"
     ]
    }
   ],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['x1', 'x2']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['y'].values, dtype=torch.float)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "print(shuffle_idx)\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent70 = int(shuffle_idx.size(0)*0.7)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent70]], X[shuffle_idx[percent70:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent70]], y[shuffle_idx[percent70:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        grad_loss_yhat = 2*(yhat - y)\n",
    "        \n",
    "        grad_yhat_weights = x\n",
    "        grad_yhat_bias = 1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat - y)**2)\n",
    "\n",
    "\n",
    "def train(model, x, y, num_epochs, learning_rate=0.01):\n",
    "    cost = []\n",
    "    prev_loss = 0\n",
    "    for e in range(num_epochs):\n",
    "        shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "        x, y = x[shuffle_idx], y[shuffle_idx]\n",
    "        #### Compute outputs ####\n",
    "        yhat = model.forward(x)\n",
    "\n",
    "        #### Compute gradients ####\n",
    "        negative_grad_w, negative_grad_b = model.backward(x, yhat, y)\n",
    "\n",
    "        #### Update weights ####\n",
    "        model.weights += learning_rate * negative_grad_w\n",
    "        model.bias += learning_rate * negative_grad_b\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x) # not that this is a bit wasteful here\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 1532.67590\n",
      "Epoch: 002 | MSE: 1312.39844\n",
      "Epoch: 003 | MSE: 1133.91809\n",
      "Epoch: 004 | MSE: 989.30280\n",
      "Epoch: 005 | MSE: 872.12598\n",
      "Epoch: 006 | MSE: 777.18109\n",
      "Epoch: 007 | MSE: 700.24927\n",
      "Epoch: 008 | MSE: 637.91254\n",
      "Epoch: 009 | MSE: 587.40167\n",
      "Epoch: 010 | MSE: 546.47284\n",
      "Epoch: 011 | MSE: 513.30811\n",
      "Epoch: 012 | MSE: 486.43430\n",
      "Epoch: 013 | MSE: 464.65805\n",
      "Epoch: 014 | MSE: 447.01224\n",
      "Epoch: 015 | MSE: 432.71323\n",
      "Epoch: 016 | MSE: 421.12637\n",
      "Epoch: 017 | MSE: 411.73697\n",
      "Epoch: 018 | MSE: 404.12827\n",
      "Epoch: 019 | MSE: 397.96255\n",
      "Epoch: 020 | MSE: 392.96603\n",
      "Epoch: 021 | MSE: 388.91705\n",
      "Epoch: 022 | MSE: 385.63589\n",
      "Epoch: 023 | MSE: 382.97684\n",
      "Epoch: 024 | MSE: 380.82202\n",
      "Epoch: 025 | MSE: 379.07571\n",
      "Epoch: 026 | MSE: 377.66052\n",
      "Epoch: 027 | MSE: 376.51367\n",
      "Epoch: 028 | MSE: 375.58423\n",
      "Epoch: 029 | MSE: 374.83099\n",
      "Epoch: 030 | MSE: 374.22055\n",
      "Epoch: 031 | MSE: 373.72586\n",
      "Epoch: 032 | MSE: 373.32492\n",
      "Epoch: 033 | MSE: 372.99997\n",
      "Epoch: 034 | MSE: 372.73660\n",
      "Epoch: 035 | MSE: 372.52316\n",
      "Epoch: 036 | MSE: 372.35019\n",
      "Epoch: 037 | MSE: 372.20996\n",
      "Epoch: 038 | MSE: 372.09637\n",
      "Epoch: 039 | MSE: 372.00424\n",
      "Epoch: 040 | MSE: 371.92963\n",
      "Epoch: 041 | MSE: 371.86917\n",
      "Epoch: 042 | MSE: 371.82010\n",
      "Epoch: 043 | MSE: 371.78036\n",
      "Epoch: 044 | MSE: 371.74814\n",
      "Epoch: 045 | MSE: 371.72205\n",
      "Epoch: 046 | MSE: 371.70090\n",
      "Epoch: 047 | MSE: 371.68372\n",
      "Epoch: 048 | MSE: 371.66983\n",
      "Epoch: 049 | MSE: 371.65860\n",
      "Epoch: 050 | MSE: 371.64941\n",
      "Epoch: 051 | MSE: 371.64200\n",
      "Epoch: 052 | MSE: 371.63602\n",
      "Epoch: 053 | MSE: 371.63116\n",
      "Epoch: 054 | MSE: 371.62720\n",
      "Epoch: 055 | MSE: 371.62405\n",
      "Epoch: 056 | MSE: 371.62143\n",
      "Epoch: 057 | MSE: 371.61932\n",
      "Epoch: 058 | MSE: 371.61765\n",
      "Epoch: 059 | MSE: 371.61624\n",
      "Epoch: 060 | MSE: 371.61511\n",
      "Epoch: 061 | MSE: 371.61423\n",
      "Epoch: 062 | MSE: 371.61349\n",
      "Epoch: 063 | MSE: 371.61288\n",
      "Epoch: 064 | MSE: 371.61240\n",
      "Epoch: 065 | MSE: 371.61200\n",
      "Epoch: 066 | MSE: 371.61172\n",
      "Epoch: 067 | MSE: 371.61142\n",
      "Epoch: 068 | MSE: 371.61121\n",
      "Epoch: 069 | MSE: 371.61108\n",
      "Epoch: 070 | MSE: 371.61090\n",
      "Epoch: 071 | MSE: 371.61084\n",
      "Epoch: 072 | MSE: 371.61075\n",
      "Epoch: 073 | MSE: 371.61066\n",
      "Epoch: 074 | MSE: 371.61057\n",
      "Epoch: 075 | MSE: 371.61053\n",
      "Epoch: 076 | MSE: 371.61050\n",
      "Epoch: 077 | MSE: 371.61047\n",
      "Epoch: 078 | MSE: 371.61047\n",
      "Epoch: 079 | MSE: 371.61044\n",
      "Epoch: 080 | MSE: 371.61041\n",
      "Epoch: 081 | MSE: 371.61035\n",
      "Epoch: 082 | MSE: 371.61041\n",
      "Epoch: 083 | MSE: 371.61038\n",
      "Epoch: 084 | MSE: 371.61041\n",
      "Epoch: 085 | MSE: 371.61035\n",
      "Epoch: 086 | MSE: 371.61035\n",
      "Epoch: 087 | MSE: 371.61035\n",
      "Epoch: 088 | MSE: 371.61032\n",
      "Epoch: 089 | MSE: 371.61035\n",
      "Epoch: 090 | MSE: 371.61035\n",
      "Epoch: 091 | MSE: 371.61035\n",
      "Epoch: 092 | MSE: 371.61032\n",
      "Epoch: 093 | MSE: 371.61035\n",
      "Epoch: 094 | MSE: 371.61035\n",
      "Epoch: 095 | MSE: 371.61032\n",
      "Epoch: 096 | MSE: 371.61035\n",
      "Epoch: 097 | MSE: 371.61035\n",
      "Epoch: 098 | MSE: 371.61032\n",
      "Epoch: 099 | MSE: 371.61035\n",
      "Epoch: 100 | MSE: 371.61032\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train, \n",
    "             num_epochs=100, \n",
    "             learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 371.61032\n",
      "Test MSE: 406.88412\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights tensor([[ 0.3623],\n",
      "        [37.8790]])\n",
      "Bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical weights tensor([[ 0.3624],\n",
      "        [37.8801]])\n",
      "Analytical bias tensor([-0.5464])\n"
     ]
    }
   ],
   "source": [
    "def analytical_solution(x, y):\n",
    "    Xb = torch.cat( (torch.ones((x.size(0), 1)), x), dim=1)\n",
    "    w = torch.zeros(x.size(1))\n",
    "    z = torch.inverse(torch.matmul(Xb.t(), Xb))\n",
    "    params = torch.matmul(z, torch.matmul(Xb.t(), y))\n",
    "    b, w = torch.tensor([params[0]]), params[1:].view(x.size(1), 1)\n",
    "    return w, b\n",
    "\n",
    "w, b = analytical_solution(X_train, y_train)\n",
    "print('Analytical weights', w)\n",
    "print('Analytical bias', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLTorch",
   "language": "python",
   "name": "dltorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
