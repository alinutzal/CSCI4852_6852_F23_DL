{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "CSCI 4852 & 6952: Deep Learning (Spring 2023)  \n",
    "\n",
    "Instructor: Alina Lazar (alazar@ysu.edu)  \n",
    "GitHub repository:https://github.com/alinutzal/CSCI-xx52-Deep-Learning-\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder for CelebA Face Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_data import get_dataloaders_celeba\n",
    "from helper_data import UnNormalize\n",
    "from helper_train import train_vae_v1\n",
    "from helper_utils import set_deterministic, set_all_seeds\n",
    "from helper_plotting import plot_accuracy, plot_training_loss\n",
    "from helper_plotting import plot_generated_images\n",
    "from helper_plotting import plot_latent_space_with_labels\n",
    "from helper_plotting import plot_images_sampled_from_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "CUDA_DEVICE_NUM = 0\n",
    "DEVICE = torch.device(f'cuda:{CUDA_DEVICE_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 123\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_deterministic\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1443490838it [00:08, 162160757.57it/s]\n",
      "26721026it [00:00, 85584854.92it/s]\n",
      "3424458it [00:00, 47842467.96it/s]\n",
      "6082035it [00:00, 67851082.75it/s]\n",
      "12156055it [00:00, 90689354.83it/s]\n",
      "2836386it [00:00, 41504289.90it/s]\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Dataset\n",
    "##########################\n",
    "\n",
    "\n",
    "custom_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.CenterCrop((128, 128)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_celeba(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_transforms=custom_transforms,\n",
    "    test_transforms=custom_transforms,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    #print(labels[:10])\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    #print(labels[:10])\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for images, labels in test_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    #print(labels[:10])\n",
    "    break\n",
    "    \n",
    "\"\"\"Targets are 40-dim vectors representing\n",
    "00 - 5_o_Clock_Shadow\n",
    "01 - Arched_Eyebrows\n",
    "02 - Attractive \n",
    "03 - Bags_Under_Eyes\n",
    "04 - Bald\n",
    "05 - Bangs\n",
    "06 - Big_Lips\n",
    "07 - Big_Nose\n",
    "08 - Black_Hair\n",
    "09 - Blond_Hair\n",
    "10 - Blurry \n",
    "11 - Brown_Hair \n",
    "12 - Bushy_Eyebrows \n",
    "13 - Chubby \n",
    "14 - Double_Chin \n",
    "15 - Eyeglasses \n",
    "16 - Goatee \n",
    "17 - Gray_Hair \n",
    "18 - Heavy_Makeup \n",
    "19 - High_Cheekbones \n",
    "20 - Male \n",
    "21 - Mouth_Slightly_Open \n",
    "22 - Mustache \n",
    "23 - Narrow_Eyes \n",
    "24 - No_Beard \n",
    "25 - Oval_Face \n",
    "26 - Pale_Skin \n",
    "27 - Pointy_Nose \n",
    "28 - Receding_Hairline \n",
    "29 - Rosy_Cheeks \n",
    "30 - Sideburns \n",
    "31 - Smiling \n",
    "32 - Straight_Hair \n",
    "33 - Wavy_Hair \n",
    "34 - Wearing_Earrings \n",
    "35 - Wearing_Hat \n",
    "36 - Wearing_Lipstick \n",
    "37 - Wearing_Necklace \n",
    "38 - Wearing_Necktie \n",
    "39 - Young         \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "\n",
    "class Trim(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :128, :128]\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.Conv2d(32, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.Conv2d(64, 64, stride=2, kernel_size=3, bias=False, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.Flatten(),\n",
    "        )    \n",
    "        \n",
    "        self.z_mean = torch.nn.Linear(4096, 200)\n",
    "        self.z_log_var = torch.nn.Linear(4096, 200)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                torch.nn.Linear(200, 4096),\n",
    "                Reshape(-1, 64, 8, 8),\n",
    "                #\n",
    "                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.ConvTranspose2d(64, 64, stride=2, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.ConvTranspose2d(64, 32, stride=2, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Dropout2d(0.25),\n",
    "                #\n",
    "                nn.ConvTranspose2d(32, 3, stride=2, kernel_size=3, padding=1),\n",
    "                #\n",
    "                Trim(),  # 3x129x129 -> 3x128x128\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "\n",
    "        \n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = torch.randn(z_mu.size(0), z_mu.size(1)).to(z_mu.get_device())\n",
    "        z = z_mu + eps * torch.exp(z_log_var/2.) \n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, z_mean, z_log_var, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "model = VAE()\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [],
   "source": [
    "log_dict = train_vae_v1(num_epochs=NUM_EPOCHS, model=model, \n",
    "                        optimizer=optimizer, device=DEVICE, \n",
    "                        train_loader=train_loader,\n",
    "                        skip_epoch_stats=True,\n",
    "                        logging_interval=50,\n",
    "                        save_model='vae_celeba_02.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(log_dict['train_reconstruction_loss_per_batch'], NUM_EPOCHS, custom_label=\" (reconstruction)\")\n",
    "plot_training_loss(log_dict['train_kl_loss_per_batch'], NUM_EPOCHS, custom_label=\" (KL)\")\n",
    "plot_training_loss(log_dict['train_combined_loss_per_batch'], NUM_EPOCHS, custom_label=\" (combined)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnormalizer = UnNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "plot_generated_images(data_loader=train_loader,\n",
    "                      model=model,\n",
    "                      #unnormalizer=unnormalizer,\n",
    "                      device=DEVICE,\n",
    "                      modeltype='VAE')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_images_sampled_from_vae(model=model, device=DEVICE, latent_size=200)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "exav100",
   "language": "python",
   "name": "exav100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
